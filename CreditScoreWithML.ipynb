{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Puntuación Crediticia\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg\" title=\"git\" width=\"100\" height=\".99\">\n",
    "\n",
    "**Modelos de Crédito**\n",
    "\n",
    "#### Mtro. Rodolfo Slay Ramos\n",
    "\n",
    "\n",
    "### Equipo:\n",
    "##### Villaseñor Rubio, Andrés\n",
    "##### Ledezma Tamez, Mauricio \n",
    "##### Sánchez Paszko, José Walden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "  <head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>Absrtact</title>\n",
    "    <style>\n",
    "      .boxed {\n",
    "        background: #F2F2F2;\n",
    "        color: black;\n",
    "        border: 3px solid #535353;\n",
    "        margin: 0px auto;\n",
    "        padding: 10px;\n",
    "        border-radius: 10px;\n",
    "      }\n",
    "    </style>\n",
    "  </head>\n",
    "  <body>\n",
    "    <!-- This is the markup of your box, in simpler terms the content structure. -->\n",
    "    <div class=\"boxed\">\n",
    "      <h3> Abstract </h2>\n",
    "      <p> En este reporte se presentan 3 propuestas diferentes usando metodologías de aprendizaje máquina (ML por sus siglas en inglés) para generar un nuevo modelo de clasificación crediticia. \n",
    "      <br>\n",
    "      La propuesta final cuenta con una precisión de XX.XX%.\n",
    "      </p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='introduction' class=\"alert alert-block alert-info\"/>\n",
    "\n",
    "## 1.- Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de clasificación crediticia ha sido un tema de gran relevancia en el sector financiero debido a la imperante necesidad de controlar y gestionar el riesgo de impago de manera eficiente. A través del tiempo, se han desarrollado múltiples modelos que emplean transformaciones lineales de distintos conjuntos de datos para establecer sistemas de puntuación, los cuales permiten segmentar a los solicitantes en grupos con características similares. Esto ha facilitado el proceso de asignación de créditos y ha contribuido a la reducción del riesgo.\n",
    "\n",
    "No obstante, si bien estas propuestas han mostrado efectividad y continúan siendo un referente en la industria, el progreso tecnológico y las herramientas emergentes de Machine Learning (ML) para la clasificación de datos han propiciado una tendencia en las instituciones financieras hacia la creación de modelos más avanzados, con arquitecturas complejas y una selección de datos optimizada.\n",
    "\n",
    "En este reporte se otorga una nueva propuesta de modelo con la intención de ayudar a la resolución de este problema, para ello se analizó una base de datos que contiene diversas variables relacionadas con el comportamiento crediticio de los usuarios. Se seleccionaron tanto variables del modelo tradicional FICO como otras nuevas, con el objetivo de obtener una representación más completa. Siendo la lista final de variables a utilizar:\n",
    "\n",
    "1. **Historial de Pagos**: Evalúa el historial previo de pagos del solicitante.\n",
    "2. **Utilización del Crédito**: Refleja qué proporción del crédito disponible ha sido utilizada.\n",
    "3. **Duración del Historial Crediticio**: Indica la antigüedad del historial crediticio del deudor.\n",
    "4. **Nuevos Créditos**: Analiza la frecuencia y reciente asunción de nuevas deudas.\n",
    "5. **Tipos de Crédito Utilizados**: Evalúa la diversidad en tipos de créditos que el solicitante ha manejado.\n",
    "6. **Deuda Pendiente**: Refleja la cantidad de deuda pendiente del solicitante.\n",
    "7. **Días de Retraso Desde la Fecha de Vencimiento**: Registra la cantidad de atrasos que el solicitante tiene en el buró de crédito.\n",
    "8. **Antigüedad del Historial Crediticio**: Muestra la duración del historial crediticio del solicitante.\n",
    "9. **Número de Tarjetas de Crédito**: Indica la cantidad de tarjetas de crédito que posee el solicitante, lo cual puede reflejar su capacidad para gestionar distintas fuentes de crédito.\n",
    "10. **Número de Préstamos**: Evalúa el número de préstamos que el solicitante ha manejado, ofreciendo una perspectiva de su experiencia ante diferentes obligaciones crediticias.\n",
    "\n",
    "En tanto al modelo, se decidió tomar diferentes aproximaciones con el fin de compararlas y mejorarlas poco a poco, siendo la primera mediante redes neuronales (NN), la siguiente un compilado de múltiples algoritmos de clasificación bastante conocidos y finalmente con un ensamble de aquellos que en la segunda aproximación hayan tenido el mejor porcentaje de éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='Análisis' class=\"alert alert-block alert-info\"/>\n",
    "\n",
    "## 2.- Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Redes Neuronales (NN)\n",
    "\n",
    "En esta propuesta, se llevó a cabo un extenso análisis utilizando distintas arquitecturas neuronales. Estas configuraciones se diseñaron para abarcar desde estructuras más simplificadas hasta las más complejas sin llegar al aprendizaje profundo, variando en número de capas, que oscilaban entre 2 y 5, y en el número de neuronas por capa, que iban desde 64 hasta 516.\n",
    "\n",
    "Uno de los aspectos más cruciales en la construcción de redes neuronales es la selección de funciones de activación, ya que estas determinan en gran medida la capacidad del modelo para capturar y representar relaciones no lineales en el conjunto de datos. Para el análisis, se utilizaron principalmente tres funciones de activación clave: ReLU, que ha sido ampliamente utilizada debido a su eficiencia y capacidad para reducir el problema de desvanecimiento del gradiente; Leaky ReLU, una variante que intenta solucionar el problema de las unidades \"muertas\" en ReLU y Mish, que es una función de activación más reciente y ha mostrado un desempeño prometedor en ciertas tareas. Además de esas, también se intentó utilizando las funciones de Tanh y Sigmoid, pero no mostraron un desempeño significativo.\n",
    "\n",
    "Con la implementación y prueba de estas diversas configuraciones, lo más destacado fue que, a pesar de las variaciones en la arquitectura y las funciones de activación, los resultados mostraron una consistencia sorprendente. La precisión de los modelos se mantuvo en un rango estrecho del 63% al 65%. Esta observación podría sugerir varios puntos: que el conjunto de datos tiene un límite inherente en cuanto a la precisión que se puede alcanzar con las arquitecturas probadas o que las funciones de activación seleccionadas tienen un comportamiento similar en este contexto específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Diversos algoritmos de clasificación\n",
    "\n",
    "Debido a la consistencia en los resultados de la propuesta anterior, se decidió experimentar con otros alogritmos de clasificación con la intención de superar el humbral de 65% en la presición, para ello, se probaron diversas configuraciones de Random Forest, K-Nearest Neighbors (KNN), Hist Gradient Boosting (HGBC), Decision Tree, Linear Discriminant Analysis, Multilayer Perceptron, Support Vector Machines, Stochastic Gradient Descent, Ridge Classifier y Logistic Regression. \n",
    "\n",
    "En esta evaluación dislumbramos que los modelos que lograron superar este humbral fueron Random Forest, KNN (con pesos por distancia y con pesos uniformes), HGBC, Decision Tree y Gradient Boosting. Siendo el mejor entre ellos Random Forest. Por lo que decidimo optimizar los parámetros para ese modelo al igual que con KNN y con HGBC. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
